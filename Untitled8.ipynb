{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxmj-CJepz7O",
        "outputId": "8fa5e8d3-c0ad-4837-a428-ea4a1c3fbf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio openai pandas numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kuv1GYKBrWlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = input(\"Enter your OpenAI API key: \").strip()\n",
        "\n",
        "if os.environ[\"OPENAI_API_KEY\"]:\n",
        "    print(\"‚úÖ API key set\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è API key is empty!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhtc9s9Mp80n",
        "outputId": "9e756718-49b0-4b44-91b6-cd54b66e58a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: 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\n",
            "‚úÖ API key set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "from openai import OpenAI\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# -----------------------------\n",
        "# OpenAI client\n",
        "# -----------------------------\n",
        "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY is not set. Please run the API key cell first.\")\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Create / Load Datasets\n",
        "# -----------------------------\n",
        "faq_data = [\n",
        "    [1,\"Orders\",\"Where can I track my order?\",\"You can track your order under the 'My Orders' section.\"],\n",
        "    [2,\"Orders\",\"How long does delivery take?\",\"Standard delivery: 3‚Äì5 days. Express: 1‚Äì2 days.\"],\n",
        "    [3,\"Orders\",\"Can I change my delivery address?\",\"Yes, within 1 hour of placing the order.\"],\n",
        "    [4,\"Payments\",\"What payment methods do you accept?\",\"We accept UPI, cards, net banking.\"],\n",
        "    [5,\"Payments\",\"Payment deducted but failed?\",\"Refunds are processed in 3‚Äì5 business days.\"],\n",
        "    [6,\"Returns\",\"Return policy?\",\"Returns accepted within 7 days of delivery.\"],\n",
        "    [7,\"Returns\",\"How do I initiate a return?\",\"Go to My Orders ‚Üí Return/Replace.\"],\n",
        "    [8,\"Account\",\"Forgot my password.\",\"Use 'Forgot Password' at login.\"],\n",
        "    [9,\"General\",\"Do you ship internationally?\",\"We currently ship only within India.\"],\n",
        "    [10,\"Support\",\"How do I contact support?\",\"Use our Help Center chat or email support@example.com.\"]\n",
        "]\n",
        "\n",
        "#faq_df = pd.DataFrame(faq_data, columns=[\"id\",\"category\",\"question\",\"answer\"])\n",
        "faq_df = pd.read_csv(\"faqs.csv\")\n",
        "products_data = [\n",
        "    [101,\"Nimbus X15 Laptop\",\"Electronics\",\"Laptop\",\"TechWave\",52000,4.4,\"work,student\",\"i5 processor, 8GB RAM, 512GB SSD\"],\n",
        "    [102,\"AuraBook Lite\",\"Electronics\",\"Laptop\",\"Skyline\",43000,4.1,\"student,budget\",\"Lightweight laptop ideal for students\"],\n",
        "    [103,\"PixelTune Earbuds\",\"Electronics\",\"Audio\",\"SoundMax\",2999,4.3,\"wireless,music\",\"Noise isolation, 24-hour battery\"],\n",
        "    [104,\"BassPro Headphones\",\"Electronics\",\"Audio\",\"SoundMax\",1799,4.0,\"gaming,music\",\"Deep bass wired headphones\"],\n",
        "    [105,\"FitTrack Pro Smartwatch\",\"Wearables\",\"Smartwatch\",\"FitTrack\",3999,4.2,\"fitness,tracking\",\"Heart-rate & step-tracker\"],\n",
        "    [106,\"UrbanMove Sneakers\",\"Fashion\",\"Footwear\",\"UrbanWalk\",2499,4.1,\"casual\",\"Daily wear sneakers\"],\n",
        "    [107,\"ComfortStride Running Shoes\",\"Fashion\",\"Footwear\",\"SprintX\",3199,4.5,\"running\",\"Extra cushioning, breathable\"],\n",
        "    [108,\"Classic Cotton T-Shirt\",\"Fashion\",\"Apparel\",\"WearWell\",699,4.0,\"casual\",\"100% cotton t-shirt\"],\n",
        "    [109,\"EcoSip Steel Bottle\",\"Home & Kitchen\",\"Bottle\",\"EcoSip\",699,4.6,\"travel,office\",\"Steel insulated bottle\"],\n",
        "    [110,\"OfficePro Ergonomic Chair\",\"Home & Office\",\"Chair\",\"SitRight\",8499,4.3,\"office\",\"Lumbar support ergonomic chair\"],\n",
        "]\n",
        "\n",
        "# product_df = pd.DataFrame(\n",
        "#     products_data,\n",
        "#     columns=[\n",
        "#         \"product_id\",\"name\",\"category\",\"subcategory\",\"brand\",\n",
        "#         \"price\",\"rating\",\"tags\",\"description\"\n",
        "#     ]\n",
        "# )\n",
        "product_df = pd.read_csv(\"products.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Support Assistant ‚Äì TF-IDF RAG\n",
        "# -----------------------------\n",
        "faq_df[\"combined\"] = faq_df[\"question\"] + \" \" + faq_df[\"answer\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "faq_tfidf = vectorizer.fit_transform(faq_df[\"combined\"])\n",
        "\n",
        "def support_assistant(query: str):\n",
        "    \"\"\"\n",
        "    Uses TF-IDF + cosine similarity to find the closest FAQ and then\n",
        "    asks the LLM to respond using that context.\n",
        "    \"\"\"\n",
        "    if not query.strip():\n",
        "        return \"Please enter a question.\", \"0.00\"\n",
        "\n",
        "    q_vec = vectorizer.transform([query])\n",
        "    sims = cosine_similarity(q_vec, faq_tfidf)[0]\n",
        "    best_idx = int(np.argmax(sims))\n",
        "    best_score = float(sims[best_idx])\n",
        "\n",
        "    row = faq_df.iloc[best_idx]\n",
        "    context = f\"Q: {row['question']}\\nA: {row['answer']}\"\n",
        "\n",
        "    escalation = best_score < 0.20\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful customer support assistant for an e-commerce store.\n",
        "\n",
        "Customer question:\n",
        "{query}\n",
        "\n",
        "FAQ context:\n",
        "{context}\n",
        "\n",
        "If the answer is clearly present, respond using it.\n",
        "If it's not clear, say you will escalate to a human agent.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\":\"user\", \"content\":prompt}],\n",
        "            temperature=0.2\n",
        "        )\n",
        "        answer = resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\", f\"{best_score:.2f}\"\n",
        "\n",
        "    if escalation:\n",
        "        answer += \"\\n\\nüì© This looks complex. I've escalated it to a human support agent.\"\n",
        "\n",
        "    return answer, f\"{best_score:.2f}\"\n",
        "\n",
        "# Wrapper for Gradio (same function signature)\n",
        "def gr_support(query):\n",
        "    return support_assistant(query)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Product Recommendation Agent\n",
        "# -----------------------------\n",
        "def recommend_products(category: str, budget: float | None, min_rating: float):\n",
        "    df = product_df.copy()\n",
        "\n",
        "    if category != \"Any\":\n",
        "        df = df[df[\"category\"] == category]\n",
        "\n",
        "    if budget is not None and budget > 0:\n",
        "        df = df[df[\"price\"] <= budget]\n",
        "\n",
        "    df = df[df[\"rating\"] >= min_rating]\n",
        "\n",
        "    if df.empty:\n",
        "        df = product_df.nlargest(3, \"rating\")\n",
        "    else:\n",
        "        df = df.sort_values([\"rating\", \"price\"], ascending=[False, True]).head(3)\n",
        "\n",
        "    return df\n",
        "\n",
        "def explain_recommendations(user_need: str, rec_df: pd.DataFrame) -> str:\n",
        "    if rec_df.empty:\n",
        "        return \"No products found.\"\n",
        "\n",
        "    products_text = \"\"\n",
        "    for _, row in rec_df.iterrows():\n",
        "        products_text += (\n",
        "            f\"- {row['name']} ({row['brand']}): ‚Çπ{row['price']}, \"\n",
        "            f\"‚≠ê {row['rating']} ‚Äì {row['description']}\\n\"\n",
        "        )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an AI product recommendation expert.\n",
        "\n",
        "User need:\n",
        "{user_need if user_need.strip() else \"Not specified\"}\n",
        "\n",
        "Recommended products:\n",
        "{products_text}\n",
        "\n",
        "Explain in simple, friendly language why these products are suitable choices.\n",
        "Keep it short and non-technical.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "def gr_product(category, budget, min_rating, user_need):\n",
        "    budget = float(budget) if budget is not None else None\n",
        "    recs = recommend_products(category, budget, min_rating)\n",
        "    explanation = explain_recommendations(user_need, recs)\n",
        "    # Return DF directly + explanation\n",
        "    return recs[[\"name\",\"brand\",\"category\",\"price\",\"rating\",\"description\"]], explanation\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Social Media Content Agent\n",
        "# -----------------------------\n",
        "def generate_social_post(brand, platform, goal, tone, offer, extra):\n",
        "    prompt = f\"\"\"\n",
        "You are a professional social media content creator.\n",
        "\n",
        "Brand: {brand}\n",
        "Platform: {platform}\n",
        "Goal: {goal}\n",
        "Tone: {tone}\n",
        "Offer: {offer or \"None\"}\n",
        "Extra details: {extra or \"None\"}\n",
        "\n",
        "Generate:\n",
        "1. A hook (1 line)\n",
        "2. Main caption (3‚Äì5 short lines)\n",
        "3. 8‚Äì12 relevant hashtags\n",
        "4. A short call-to-action\n",
        "\n",
        "Format it nicely.\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "def generate_content_plan(brand, platform, goal, days: int = 7):\n",
        "    prompt = f\"\"\"\n",
        "Create a {days}-day content plan for:\n",
        "\n",
        "Brand: {brand}\n",
        "Platform: {platform}\n",
        "Goal: {goal}\n",
        "\n",
        "For each day, provide:\n",
        "- Theme/Idea\n",
        "- Recommended format (post, reel, story, carousel, etc.)\n",
        "- 1-line description\n",
        "\n",
        "Return it as a bullet list, one bullet per day.\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "            temperature=0.6\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "def gr_social_single(brand, platform, goal, tone, offer, extra):\n",
        "    return generate_social_post(brand, platform, goal, tone, offer, extra)\n",
        "\n",
        "def gr_social_plan(brand, platform, goal):\n",
        "    return generate_content_plan(brand, platform, goal, days=7)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Build Gradio UI\n",
        "# -----------------------------\n",
        "categories = [\"Any\"] + sorted(product_df[\"category\"].unique().tolist())\n",
        "\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"# ü§ñ AI Agent Suite ‚Äì Sales, Marketing & Support\\n\"\n",
        "        \"Three agents in one app: **Support Assistant**, **Product Recommender**, \"\n",
        "        \"and **Social Media Content Generator**.\"\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"üõü Support Assistant\"):\n",
        "        gr.Markdown(\"Ask any question related to orders, payments, returns, or account.\")\n",
        "        support_input = gr.Textbox(label=\"Customer Question\", lines=3, placeholder=\"Example: How can I track my order?\")\n",
        "        support_answer = gr.Textbox(label=\"AI Answer\")\n",
        "        support_conf = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "\n",
        "        support_button = gr.Button(\"Get Answer\")\n",
        "        support_button.click(\n",
        "            fn=gr_support,\n",
        "            inputs=support_input,\n",
        "            outputs=[support_answer, support_conf]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üõí Product Recommendation\"):\n",
        "        gr.Markdown(\"Get product suggestions based on category, budget, and rating.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            prod_cat = gr.Dropdown(choices=categories, value=\"Any\", label=\"Category\")\n",
        "            prod_budget = gr.Number(value=5000, label=\"Max Budget (‚Çπ)\")\n",
        "            prod_rating = gr.Slider(minimum=1.0, maximum=5.0, value=4.0, step=0.1, label=\"Minimum Rating\")\n",
        "\n",
        "        user_need = gr.Textbox(\n",
        "            label=\"User Need (optional but recommended)\",\n",
        "            lines=3,\n",
        "            placeholder=\"Example: I need a lightweight laptop for online classes.\"\n",
        "        )\n",
        "\n",
        "        prod_table = gr.Dataframe(\n",
        "            label=\"Top Recommendations\",\n",
        "            headers=[\"name\",\"brand\",\"category\",\"price\",\"rating\",\"description\"],\n",
        "            row_count=3,\n",
        "            col_count=6\n",
        "        )\n",
        "        prod_explanation = gr.Textbox(label=\"Why These Products?\", lines=6)\n",
        "\n",
        "        prod_button = gr.Button(\"Recommend Products\")\n",
        "        prod_button.click(\n",
        "            fn=gr_product,\n",
        "            inputs=[prod_cat, prod_budget, prod_rating, user_need],\n",
        "            outputs=[prod_table, prod_explanation]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üì£ Social Media Generator\"):\n",
        "        gr.Markdown(\"Generate captions and a 7-day content plan.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            brand = gr.Textbox(label=\"Brand Name\", value=\"ShopSmart\")\n",
        "            platform = gr.Dropdown(\n",
        "                choices=[\"Instagram\", \"Facebook\", \"LinkedIn\", \"Twitter/X\", \"YouTube\"],\n",
        "                value=\"Instagram\",\n",
        "                label=\"Platform\"\n",
        "            )\n",
        "        with gr.Row():\n",
        "            tone = gr.Dropdown(\n",
        "                choices=[\"Friendly\", \"Professional\", \"Bold\", \"Fun\", \"Educational\"],\n",
        "                value=\"Friendly\",\n",
        "                label=\"Tone\"\n",
        "            )\n",
        "            goal = gr.Textbox(\n",
        "                label=\"Campaign Goal\",\n",
        "                value=\"Increase awareness for our festive sale.\"\n",
        "            )\n",
        "\n",
        "        offer = gr.Textbox(label=\"Offer / Highlight (optional)\", value=\"Flat 30% OFF on selected items.\")\n",
        "        extra = gr.Textbox(label=\"Extra Details (optional)\", placeholder=\"Target audience, key products, etc.\")\n",
        "\n",
        "        social_post_out = gr.Textbox(label=\"Generated Post\", lines=10)\n",
        "        social_plan_out = gr.Textbox(label=\"7-Day Content Plan\", lines=12)\n",
        "\n",
        "        with gr.Row():\n",
        "            btn_post = gr.Button(\"Generate Single Post\")\n",
        "            btn_plan = gr.Button(\"Generate 7-Day Content Plan\")\n",
        "\n",
        "        btn_post.click(\n",
        "            fn=gr_social_single,\n",
        "            inputs=[brand, platform, goal, tone, offer, extra],\n",
        "            outputs=social_post_out\n",
        "        )\n",
        "\n",
        "        btn_plan.click(\n",
        "            fn=gr_social_plan,\n",
        "            inputs=[brand, platform, goal],\n",
        "            outputs=social_plan_out\n",
        "        )\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "v8VAJYJpqLUd",
        "outputId": "72f46825-b95f-4411-a6fc-40c13c87a7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3437334951.py:249: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=\"soft\") as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://46ebc1fd0a3a919c67.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://46ebc1fd0a3a919c67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "try:\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hello, test message\"}],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    print(\"‚úÖ API call success. Response:\")\n",
        "    print(resp.choices[0].message.content)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå API call failed.\")\n",
        "    print(repr(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RWZZ1YZPk-z",
        "outputId": "b8c894f8-49c1-455b-c073-553e7d1af2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API call success. Response:\n",
            "Hello! Your message has been received. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "\n",
        "from openai import OpenAI\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 0. OpenAI client\n",
        "# -----------------------------\n",
        "def get_openai_client():\n",
        "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\n",
        "            \"OPENAI_API_KEY is not set.\\n\\n\"\n",
        "            \"Set it before running the app, for example:\\n\"\n",
        "            \"  import os\\n\"\n",
        "            \"  os.environ['OPENAI_API_KEY'] = 'sk-...'\\n\"\n",
        "        )\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "client = get_openai_client()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load Datasets from CSV\n",
        "# -----------------------------\n",
        "def load_faq_csv(path: str = \"faqs.csv\") -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"FAQ file '{path}' not found. \"\n",
        "            f\"Make sure faqs.csv is in the same directory as this script / notebook.\"\n",
        "        )\n",
        "    df = pd.read_csv(path)\n",
        "    required_cols = {\"id\", \"category\", \"question\", \"answer\"}\n",
        "    if not required_cols.issubset(df.columns):\n",
        "        raise ValueError(\n",
        "            f\"faqs.csv must contain columns: {required_cols}. \"\n",
        "            f\"Found: {df.columns.tolist()}\"\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_products_csv(path: str = \"products.csv\") -> pd.DataFrame:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Products file '{path}' not found. \"\n",
        "            f\"Make sure products.csv is in the same directory as this script / notebook.\"\n",
        "        )\n",
        "    df = pd.read_csv(path)\n",
        "    required_cols = {\n",
        "        \"product_id\",\n",
        "        \"name\",\n",
        "        \"category\",\n",
        "        \"subcategory\",\n",
        "        \"brand\",\n",
        "        \"price\",\n",
        "        \"rating\",\n",
        "        \"tags\",\n",
        "        \"description\",\n",
        "    }\n",
        "    if not required_cols.issubset(df.columns):\n",
        "        raise ValueError(\n",
        "            f\"products.csv must contain columns: {required_cols}. \"\n",
        "            f\"Found: {df.columns.tolist()}\"\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "faq_df = load_faq_csv(\"faqs.csv\")\n",
        "product_df = load_products_csv(\"products.csv\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Support Assistant ‚Äì TF-IDF RAG\n",
        "# -----------------------------\n",
        "# Safely combine question + answer as string\n",
        "faq_df[\"question\"] = faq_df[\"question\"].astype(str)\n",
        "faq_df[\"answer\"] = faq_df[\"answer\"].astype(str)\n",
        "faq_df[\"combined\"] = faq_df[\"question\"] + \" \" + faq_df[\"answer\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "faq_tfidf = vectorizer.fit_transform(faq_df[\"combined\"])\n",
        "\n",
        "\n",
        "def support_assistant(query: str):\n",
        "    \"\"\"\n",
        "    Uses TF-IDF + cosine similarity to find the closest FAQ and then\n",
        "    asks the LLM to respond using that context.\n",
        "    Returns: (answer_text, similarity_score_str)\n",
        "    \"\"\"\n",
        "    query = (query or \"\").strip()\n",
        "    if not query:\n",
        "        return \"Please enter a question.\", \"0.00\"\n",
        "\n",
        "    # --- Similarity search over FAQ ---\n",
        "    try:\n",
        "        q_vec = vectorizer.transform([query])\n",
        "        sims = cosine_similarity(q_vec, faq_tfidf)[0]\n",
        "        best_idx = int(np.argmax(sims))\n",
        "        best_score = float(sims[best_idx])\n",
        "\n",
        "        row = faq_df.iloc[best_idx]\n",
        "        context = f\"Q: {row['question']}\\nA: {row['answer']}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error while searching FAQ data: {e}\", \"0.00\"\n",
        "\n",
        "    escalation = best_score < 0.20  # threshold for escalation\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful customer support assistant for an e-commerce store.\n",
        "\n",
        "Customer question:\n",
        "{query}\n",
        "\n",
        "FAQ context:\n",
        "{context}\n",
        "\n",
        "If the answer is clearly present, respond using it.\n",
        "If it's not clear, say you will escalate to a human agent.\n",
        "\"\"\"\n",
        "\n",
        "    # --- Call OpenAI Chat API ---\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.2,\n",
        "        )\n",
        "        answer = resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\", f\"{best_score:.2f}\"\n",
        "\n",
        "    if escalation:\n",
        "        answer += (\n",
        "            \"\\n\\nüì© This looks complex. I've escalated it to a human support agent.\"\n",
        "        )\n",
        "\n",
        "    return answer, f\"{best_score:.2f}\"\n",
        "\n",
        "\n",
        "def gr_support(query: str):\n",
        "    return support_assistant(query)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Product Recommendation Agent\n",
        "# -----------------------------\n",
        "def recommend_products(category: str, budget: float | None, min_rating: float):\n",
        "    \"\"\"\n",
        "    Filter products by category, budget, and rating.\n",
        "    Returns top 3 by rating (and then price).\n",
        "    \"\"\"\n",
        "    df = product_df.copy()\n",
        "\n",
        "    # Normalize column types\n",
        "    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
        "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"price\", \"rating\"])\n",
        "\n",
        "    if category and category != \"Any\":\n",
        "        df = df[df[\"category\"] == category]\n",
        "\n",
        "    if budget is not None and budget > 0:\n",
        "        df = df[df[\"price\"] <= budget]\n",
        "\n",
        "    df = df[df[\"rating\"] >= min_rating]\n",
        "\n",
        "    if df.empty:\n",
        "        df = product_df.copy()\n",
        "        df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
        "        df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
        "        df = df.dropna(subset=[\"price\", \"rating\"])\n",
        "        df = df.nlargest(3, \"rating\")\n",
        "    else:\n",
        "        df = df.sort_values([\"rating\", \"price\"], ascending=[False, True]).head(3)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def explain_recommendations(user_need: str, rec_df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Use LLM to explain why the recommended products are suitable.\n",
        "    \"\"\"\n",
        "    if rec_df.empty:\n",
        "        return \"No products found.\"\n",
        "\n",
        "    products_text = \"\"\n",
        "    for _, row in rec_df.iterrows():\n",
        "        products_text += (\n",
        "            f\"- {row['name']} ({row['brand']}): ‚Çπ{row['price']}, \"\n",
        "            f\"‚≠ê {row['rating']} ‚Äì {row['description']}\\n\"\n",
        "        )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an AI product recommendation expert.\n",
        "\n",
        "User need:\n",
        "{user_need if user_need and user_need.strip() else \"Not specified\"}\n",
        "\n",
        "Recommended products:\n",
        "{products_text}\n",
        "\n",
        "Explain in simple, friendly language why these products are suitable choices.\n",
        "Keep it short and non-technical.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "\n",
        "def gr_product(category, budget, min_rating, user_need):\n",
        "    try:\n",
        "        budget_val = float(budget) if budget is not None else None\n",
        "    except (TypeError, ValueError):\n",
        "        budget_val = None\n",
        "\n",
        "    recs = recommend_products(category, budget_val, float(min_rating))\n",
        "    explanation = explain_recommendations(user_need, recs)\n",
        "\n",
        "    display_df = recs[\n",
        "        [\"name\", \"brand\", \"category\", \"price\", \"rating\", \"description\"]\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "    return display_df, explanation\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Social Media Content Agent\n",
        "# -----------------------------\n",
        "def generate_social_post(\n",
        "    brand, platform, goal, tone, offer, extra\n",
        "):\n",
        "    prompt = f\"\"\"\n",
        "You are a professional social media content creator.\n",
        "\n",
        "Brand: {brand}\n",
        "Platform: {platform}\n",
        "Goal: {goal}\n",
        "Tone: {tone}\n",
        "Offer: {offer or \"None\"}\n",
        "Extra details: {extra or \"None\"}\n",
        "\n",
        "Generate:\n",
        "1. A hook (1 line)\n",
        "2. Main caption (3‚Äì5 short lines)\n",
        "3. 8‚Äì12 relevant hashtags\n",
        "4. A short call-to-action\n",
        "\n",
        "Format it nicely.\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "\n",
        "def generate_content_plan(brand, platform, goal, days: int = 7):\n",
        "    prompt = f\"\"\"\n",
        "Create a {days}-day content plan for:\n",
        "\n",
        "Brand: {brand}\n",
        "Platform: {platform}\n",
        "Goal: {goal}\n",
        "\n",
        "For each day, provide:\n",
        "- Theme/Idea\n",
        "- Recommended format (post, reel, story, carousel, etc.)\n",
        "- 1-line description\n",
        "\n",
        "Return it as a bullet list, one bullet per day.\n",
        "\"\"\"\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.6,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "\n",
        "def gr_social_single(brand, platform, goal, tone, offer, extra):\n",
        "    return generate_social_post(brand, platform, goal, tone, offer, extra)\n",
        "\n",
        "\n",
        "def gr_social_plan(brand, platform, goal):\n",
        "    return generate_content_plan(brand, platform, goal, days=7)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Build Gradio UI\n",
        "# -----------------------------\n",
        "product_categories = (\n",
        "    sorted(product_df[\"category\"].dropna().astype(str).unique().tolist())\n",
        "    if \"category\" in product_df.columns\n",
        "    else []\n",
        ")\n",
        "categories = [\"Any\"] + product_categories\n",
        "\n",
        "with gr.Blocks(theme=\"soft\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"# ü§ñ AI Agent Suite ‚Äì Sales, Marketing & Support\\n\"\n",
        "        \"Three agents in one app: **Support Assistant**, **Product Recommender**, \"\n",
        "        \"and **Social Media Content Generator**.\"\n",
        "    )\n",
        "\n",
        "    # --- Support Assistant Tab ---\n",
        "    with gr.Tab(\"üõü Support Assistant\"):\n",
        "        gr.Markdown(\"Ask any question related to orders, payments, returns, or account.\")\n",
        "        support_input = gr.Textbox(\n",
        "            label=\"Customer Question\",\n",
        "            lines=3,\n",
        "            placeholder=\"Example: How can I track my order?\",\n",
        "        )\n",
        "        support_answer = gr.Textbox(label=\"AI Answer\")\n",
        "        support_conf = gr.Textbox(label=\"Similarity Score\", interactive=False)\n",
        "\n",
        "        support_button = gr.Button(\"Get Answer\")\n",
        "        support_button.click(\n",
        "            fn=gr_support,\n",
        "            inputs=support_input,\n",
        "            outputs=[support_answer, support_conf],\n",
        "        )\n",
        "\n",
        "    # --- Product Recommendation Tab ---\n",
        "    with gr.Tab(\"üõí Product Recommendation\"):\n",
        "        gr.Markdown(\"Get product suggestions based on category, budget, and rating.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            prod_cat = gr.Dropdown(\n",
        "                choices=categories, value=\"Any\", label=\"Category\"\n",
        "            )\n",
        "            prod_budget = gr.Number(value=5000, label=\"Max Budget (‚Çπ)\")\n",
        "            prod_rating = gr.Slider(\n",
        "                minimum=1.0, maximum=5.0, value=4.0, step=0.1, label=\"Minimum Rating\"\n",
        "            )\n",
        "\n",
        "        user_need = gr.Textbox(\n",
        "            label=\"User Need (optional but recommended)\",\n",
        "            lines=3,\n",
        "            placeholder=\"Example: I need a lightweight laptop for online classes.\",\n",
        "        )\n",
        "\n",
        "        prod_table = gr.Dataframe(\n",
        "            label=\"Top Recommendations\",\n",
        "            headers=[\n",
        "                \"name\",\n",
        "                \"brand\",\n",
        "                \"category\",\n",
        "                \"price\",\n",
        "                \"rating\",\n",
        "                \"description\",\n",
        "            ],\n",
        "            row_count=3,\n",
        "            col_count=6,\n",
        "        )\n",
        "        prod_explanation = gr.Textbox(label=\"Why These Products?\", lines=6)\n",
        "\n",
        "        prod_button = gr.Button(\"Recommend Products\")\n",
        "        prod_button.click(\n",
        "            fn=gr_product,\n",
        "            inputs=[prod_cat, prod_budget, prod_rating, user_need],\n",
        "            outputs=[prod_table, prod_explanation],\n",
        "        )\n",
        "\n",
        "    # --- Social Media Generator Tab ---\n",
        "    with gr.Tab(\"üì£ Social Media Generator\"):\n",
        "        gr.Markdown(\"Generate captions and a 7-day content plan.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            brand = gr.Textbox(label=\"Brand Name\", value=\"ShopSmart\")\n",
        "            platform = gr.Dropdown(\n",
        "                choices=[\"Instagram\", \"Facebook\", \"LinkedIn\", \"Twitter/X\", \"YouTube\"],\n",
        "                value=\"Instagram\",\n",
        "                label=\"Platform\",\n",
        "            )\n",
        "        with gr.Row():\n",
        "            tone = gr.Dropdown(\n",
        "                choices=[\"Friendly\", \"Professional\", \"Bold\", \"Fun\", \"Educational\"],\n",
        "                value=\"Friendly\",\n",
        "                label=\"Tone\",\n",
        "            )\n",
        "            goal = gr.Textbox(\n",
        "                label=\"Campaign Goal\",\n",
        "                value=\"Increase awareness for our festive sale.\",\n",
        "            )\n",
        "\n",
        "        offer = gr.Textbox(\n",
        "            label=\"Offer / Highlight (optional)\",\n",
        "            value=\"Flat 30% OFF on selected items.\",\n",
        "        )\n",
        "        extra = gr.Textbox(\n",
        "            label=\"Extra Details (optional)\",\n",
        "            placeholder=\"Target audience, key products, etc.\",\n",
        "        )\n",
        "\n",
        "        social_post_out = gr.Textbox(label=\"Generated Post\", lines=10)\n",
        "        social_plan_out = gr.Textbox(label=\"7-Day Content Plan\", lines=12)\n",
        "\n",
        "        with gr.Row():\n",
        "            btn_post = gr.Button(\"Generate Single Post\")\n",
        "            btn_plan = gr.Button(\"Generate 7-Day Content Plan\")\n",
        "\n",
        "        btn_post.click(\n",
        "            fn=gr_social_single,\n",
        "            inputs=[brand, platform, goal, tone, offer, extra],\n",
        "            outputs=social_post_out,\n",
        "        )\n",
        "\n",
        "        btn_plan.click(\n",
        "            fn=gr_social_plan,\n",
        "            inputs=[brand, platform, goal],\n",
        "            outputs=social_plan_out,\n",
        "        )\n",
        "\n",
        "\n",
        "# For local run: python app_gradio.py\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "Jqm9yqhsQVaM",
        "outputId": "48072150-563d-4daa-c3d1-37c7405fa278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2451895910.py:318: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=\"soft\") as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6e69907dadc19b93f2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6e69907dadc19b93f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}